# Assignment 2 : CodeT5: Training a Transformer model for Predicting if statements

1. Model Checkpoint-2030-https://drive.google.com/drive/folders/1Clo230JaRyDeZKLdvDHPkjBj_UnrvHqU?usp=sharing
2. Model Checkpoint-2000 - https://drive.google.com/drive/folders/10wl6dJwrBPS2U5VZfGpDZ4TLf91tBrnw?usp=sharing
3. Model Checkpoint-50- https://drive.google.com/drive/folders/1g4K3JMzbkAPxef_wOC6eDwyv-xUA4s0X?usp=sharing

## Introduction
This project enhances the CodeT5 model's ability to predict if conditions in Python code through specialized pre-training and fine-tuning phases. The dataset derived from CodeXGLUE was fine-tuned over 10 epochs, focusing on identifying and inserting logical conditions accurately. Output evaluations for three checkpoints are available in CSV format, showcasing the model's performance on the entire dataset, though only the first five indices are detailed in the CSV files. This README provides an overview of the methodologies and key findings, guiding users through the project's structured approach and its implications for automated coding tools.

## Table of Contents
- [Project Title](#project-title)
- [Introduction](#introduction)
- [Table of Contents](#table-of-contents)
- [Getting Started](#getting-started)
  - [Dependencies](#dependencies)
  - [Installation](#installation)
- [Usage](#usage)
  - [Pre-training](#pre-training)
  - [Fine-tuning](#fine-tuning)
  - [Generating Predictions](#generating-predictions)
- [Outputs](#outputs)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)

## Getting Started

### Dependencies
Describe any prerequisites, libraries, or any other dependencies.

### Installation
Step-by-step series of examples and explanations about how to get a development env running.

```bash
git clone https://yourrepositorylinkhere.com
cd your-project-name
pip install -r requirements.txt


